---
title: "Sentiment Analysis of Customer Complaints"
output: html_notebook
---



```{r}
# Create environment
library(tidyverse)
library(DataComputing)
library(mosaic)
library(monkeylearn)
library(knitr)
library(glue)
library(ggplot2)

```



```{r}
library(readxl)
CustomerComplaints <- read.csv("C:/Users/smazeski/Desktop/WinterData/CustomerComplaints.csv")
head(CustomerComplaints)
```

Total Customer Credits Given in 2019
```{r}
# Find sum of credit given to customers in 2019

CustomerComplaintCost <- CustomerComplaints %>% summarise(TotalCredits = sum(CREDIT, na.rm = TRUE))
CustomerComplaintCost

```

```{r}
HighPercentComplaint <- CustomerComplaints %>% group_by(ITEM_NUMBER) %>% filter(THEPERCENTAGE > 5) %>% select(ITEM_NUMBER, TOTAL_ORDERED, TOTAL_COMPLAINTS, THEPERCENTAGE, CREDIT) %>% arrange(desc(THEPERCENTAGE))
Next <- HighPercentComplaint %>% replace(is.na(.), 0) %>% mutate(SumCredit = sum(CREDIT))

Final <- Next %>% select(ITEM_NUMBER, TOTAL_ORDERED, TOTAL_COMPLAINTS, THEPERCENTAGE, SumCredit) %>% arrange(SumCredit)
unduplicated <- unique(Final)
view(unduplicated)
write.table(unduplicated, "C:/Users/smazeski/Desktop/mydata.xlsx", sep = ",")
```






```{r}
CreditByItem <- CustomerComplaints %>% group_by(ITEM_NUMBER) %>% summarise(Credit = sum(CREDIT)) %>% arrange(Credit)
head(ComplaintByItem)

```

Filtering out common words in order to look into some more frequency of comments
```{r}
WordFreq <- data.frame(table(unlist(strsplit(tolower(CustomerComplaints$DETAILS), " "))))
WordFreq <- WordFreq %>% filter(Var1 != 'the' & Var1 != 'not' & Var1 != 'and' & Var1 != 'to' & Var1 != 'is' & Var1 != 'on' & Var1 != 'of' & Var1 != 'a' & Var1 != 'in' & Var1 != 'for' & Var1 != '' & Var1 != 'customer' & Var1 != 'with' & Var1 != 'it' & Var1 != 'was' & Var1 != 'are' & Var1 != 'they' & Var1 != 'that' & Var1 != '-'& Var1 != 'as' & Var1 != 'this' & Var1 != 'no' & Var1 != 'but' & Var1 != 'were' & Var1 != 'one'& Var1 != 'from' & Var1 != 'per' & Var1 != 'unit' & Var1 != 'item' & Var1 != 'will'& Var1 != 'has' & Var1 != 'have'& Var1 != 'does' & Var1 != 'cust' & Var1 != 'sc' & Var1 != 'all'& Var1 != 'be' & Var1 != 'said'& Var1 != 'at'& Var1 != 'when' & Var1 != 'after' & Var1 != 'we'& Var1 != 'by' & Var1 != 'had' & Var1 != 'up' & Var1 != 'off') %>% arrange(desc(Freq))
head(WordFreq, 20)
```
```{r}
# Further Text Procoessing
data <- WordFreq[1:20,]
ggplot(data=data,aes(x=reorder(Var1,Freq),y=Freq ))+geom_bar(stat='identity',position='stack', width=.9) + theme(axis.text.x=element_text(angle=60,hjust=1)) 
```
